# ==========================================
# MMDL Project Configuration (Enhanced)
# ==========================================

# 프로젝트 루트 경로
ROOT_DIR: "./"

# 데이터셋 경로
COCO_DIR_NAME: "coco2017"
KITTI_DIR_NAME: "kitti"

# [FIX] 누락된 DATA_URLS 추가
DATA_URLS:
  IMAGES_ZIP: "http://images.cocodataset.org/zips/train2017.zip"
  ANN_ZIP: "http://images.cocodataset.org/annotations/annotations_trainval2017.zip"

# 모델 설정
TEACHER_MODEL: "convnext_base_w"
TEACHER_PRETRAIN: "laion2b_s13b_b82k"
TEACHER_WEIGHTS_PATH: "teacher_talk2car_adapted.pth"  # Stage 0 결과물

# STUDENT_MODEL_BACKBONE: "convnext_tiny"  # or "convnext_tiny_multiscale"
STUDENT_MODEL_BACKBONE: "convnext_tiny_multiscale"
STUDENT_WEIGHTS_PATH: "results/latest/distilled_weights.pth"

# 이미지 설정
# IMAGE_SIZE: 224
# IMAGE_SIZE: 384  
IMAGE_SIZE: 448
# IMAGE_SIZE: 512

# Stage 1: COCO Distillation 설정
MAX_IMAGES_TRAINING: null  # null이면 전체 사용

# COCO Region 필터링
MIN_AREA_RATIO: 0.01  # 최소 객체 크기 (이미지 대비)
SMALL_ONLY: false     # true면 작은 객체만 사용

# 타겟 클래스 (COCO)
TARGET_CLASS_NAMES:
  - "person"
  - "bicycle"
  - "car"
  - "motorcycle"
  - "bus"
  - "truck"
  - "traffic light"
  - "stop sign"

# Stage 0: Teacher Domain Adaptation (NEW)
TEACHER_ADAPTATION:
  ENABLED: true
  NUM_EPOCHS: 5
  LEARNING_RATE: 5e-6
  BATCH_SIZE: 32

# Stage 1 학습 하이퍼파라미터
TRAIN:
  BATCH_SIZE: 8
  ACCUMULATION_STEPS: 4
  NUM_EPOCHS: 10
  LEARNING_RATE: 1e-4
  WEIGHT_DECAY: 0.01
  NUM_WORKERS: 8
  TEMPERATURE: 0.07
  
  # Loss 가중치 (InfoNCE + SimKD + PostCosine)
  LOSS_WEIGHTS:
    w_clip: 1.0   # InfoNCE (필수)
    w_sim: 0.5    # Similarity-KD (선택)
    w_cos: 0.3    # Post-Cosine (선택)

# Stage 1 평가 설정
EVAL:
  MAX_BANK_BATCHES: 100  # Region Bank 크기
  TOP_K: 10              # Recall@K

# Data Augmentation (NEW)
AUGMENTATION:
  USE_ALBUMENTATIONS: true
  HORIZONTAL_FLIP: 0.5
  COLOR_JITTER: 0.5
  ROTATION: 5
  SHIFT_SCALE: 0.05
  NOISE_BLUR: 0.3

DOMAIN_OVERSAMPLE_RATI: 5

# Stage 2: Talk2Car Fine-tuning 설정 (통합됨)
TALK2CAR:
  DIR_NAME: "Talk2Car/data"
  ANNOTATION_FILE: "Talk2Car_bbox.json" # (참고용)
  VIS_COUNT: 50  # 시각화할 샘플 수
  HEAD_TYPE: "Transformer"  # "Projection" or "Transformer"
  
  FINE_TUNE:
    BATCH_SIZE: 32
    NUM_EPOCHS: 60
    LEARNING_RATE: 1e-4
    NUM_WORKERS: 4
    
    # Loss 가중치 (L1 + GIoU)
    LOSS_WEIGHTS:
      w_l1: 5.0
      w_giou: 2.0
    
    # Focal Loss (선택적)
    USE_FOCAL: false
    FOCAL_GAMMA: 2.0

